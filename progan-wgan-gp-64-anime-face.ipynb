{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":432296,"sourceType":"datasetVersion","datasetId":195056},{"sourceId":2270092,"sourceType":"datasetVersion","datasetId":1366867}],"dockerImageVersionId":30788,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from PIL import Image\nimport os\nfrom tqdm import tqdm\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport keras\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, LeakyReLU, Reshape, Flatten, Input\nfrom keras.layers import Add,Layer,UpSampling2D,Conv2D, MaxPooling2D, Activation, Dropout, Conv2DTranspose,BatchNormalization,SpectralNormalization,AveragePooling2D\nfrom keras import layers\nimport tensorflow as tf\nimport time\nfrom IPython import display\n#import cv2\nimport shutil\nimport gc\nfrom tensorflow.keras import backend as K\nfrom concurrent.futures import ThreadPoolExecutor\nfrom keras.applications.inception_v3 import InceptionV3\nfrom skimage.transform import resize\nfrom scipy.linalg import sqrtm\n\nimport math","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-11-27T18:16:30.844588Z","iopub.execute_input":"2024-11-27T18:16:30.845392Z","iopub.status.idle":"2024-11-27T18:16:47.625330Z","shell.execute_reply.started":"2024-11-27T18:16:30.845332Z","shell.execute_reply":"2024-11-27T18:16:47.623991Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Hyperparameters","metadata":{}},{"cell_type":"code","source":"## hyper parmeters\ndataset_path = \"/kaggle/input/anime-faces/data/data\"\nsave_train_loaction = \"./train\"\nimage_shape = (64,64,3)\nBUFFER_SIZE = 23000\n\nnoise_dim = 256\nnum_examples_to_generate = 25\nlearning_rate = 0.0001\nCheckpointInterval = 1 #In epoch terms\nOutputInterval = 1  # In epoch how often to show output\nImageSaveInterval = 1 #Subset of above i.e. >= OutputInterval\n#old_checkpoint_location = \"/kaggle/input/progress-1/train\"\nold_checkpoint_location = None\nsteps_per_epoch = 20300// 32\nno_blocks = int(math.log2(image_shape[1])) - 1\nn_batch = [32, 32, 16, 8, 8, 8,8]\nEpochs = [20,20,40,40,100,100]\n\n\nGP_WEIGHT = 1.0\n\n\nUSE_PIPELINING = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T18:18:32.144712Z","iopub.execute_input":"2024-11-27T18:18:32.145207Z","iopub.status.idle":"2024-11-27T18:18:32.153271Z","shell.execute_reply.started":"2024-11-27T18:18:32.145168Z","shell.execute_reply":"2024-11-27T18:18:32.151850Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"while len(n_batch) < no_blocks:\n    n_batch.append(n_batch[-1])\nwhile len(Epochs) < no_blocks:\n    Epochs.append(Epochs[-1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:26:50.516524Z","iopub.execute_input":"2024-11-17T15:26:50.516762Z","iopub.status.idle":"2024-11-17T15:26:50.528759Z","shell.execute_reply.started":"2024-11-17T15:26:50.516739Z","shell.execute_reply":"2024-11-17T15:26:50.528179Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"try:\n    # Try to detect and initialize a TPU\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # Detect TPU\n    tf.tpu.experimental.initialize_tpu_system(tpu)  # Initialize TPU\n    tpu_strategy = tf.distribute.TPUStrategy(tpu)  # Use TPU strategy\n    print(\"Running on TPU\")\nexcept ValueError:\n    # If TPU is not available, fall back to GPU or CPU\n    tpu_strategy = tf.distribute.MirroredStrategy()  # Use GPU or CPU strategy\n    print(\"Running on GPU or CPU\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:26:50.529532Z","iopub.execute_input":"2024-11-17T15:26:50.529770Z","iopub.status.idle":"2024-11-17T15:26:59.281163Z","shell.execute_reply.started":"2024-11-17T15:26:50.529747Z","shell.execute_reply":"2024-11-17T15:26:59.280192Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## since for input we have another directory therefore there is different location and this check is needed \n# after headless run\nif old_checkpoint_location is not None and not os.path.isdir(save_train_loaction):\n    print(\"Old CheckPoint Location - Copied to current working/output directory\")\n    shutil.copytree(old_checkpoint_location, save_train_loaction, dirs_exist_ok=True)\nelse:\n    print(\"Initializing from scratch.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:26:59.282354Z","iopub.execute_input":"2024-11-17T15:26:59.282897Z","iopub.status.idle":"2024-11-17T15:26:59.287596Z","shell.execute_reply.started":"2024-11-17T15:26:59.282866Z","shell.execute_reply":"2024-11-17T15:26:59.286777Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.makedirs(save_train_loaction, exist_ok=True)\nos.makedirs(save_train_loaction+\"/images\", exist_ok=True)\nos.makedirs(save_train_loaction+\"/model\", exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:26:59.288537Z","iopub.execute_input":"2024-11-17T15:26:59.288780Z","iopub.status.idle":"2024-11-17T15:26:59.302335Z","shell.execute_reply.started":"2024-11-17T15:26:59.288757Z","shell.execute_reply":"2024-11-17T15:26:59.301510Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## helper function\ndef has_file_with_prefix(directory, prefix):\n    # Check if the directory exists\n    if not os.path.isdir(directory):\n        return False\n\n    # Iterate over files in the directory\n    for filename in os.listdir(directory):\n        if filename.startswith(prefix):\n            return True\n    return False\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:26:59.303346Z","iopub.execute_input":"2024-11-17T15:26:59.303602Z","iopub.status.idle":"2024-11-17T15:26:59.314817Z","shell.execute_reply.started":"2024-11-17T15:26:59.303576Z","shell.execute_reply":"2024-11-17T15:26:59.313898Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_and_preprocess_image(image_path):\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_jpeg(image, channels=3)  # Decode JPEG image\n    image = tf.image.resize(image, (image_shape[0],image_shape[1]))  # Resize to desired shape\n    image = (image /127.5) - 1  # Normalize to [-1, 1] for DCGAN compatibility\n    return image\n\n\n\ndef change_dataset(new_shape,batch_size,dataset):\n    dataset = dataset.map(lambda x: tf.image.resize(x, new_shape), num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.unbatch()\n    dataset = dataset.batch(batch_size, drop_remainder=True)\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)  # Prefetch for optimal loading\n    return dataset.repeat() \n    \ndef create_image_dataset(data_dir, batch_size=32, shuffle_buffer_size=1000):\n    # Load file paths for all images\n    dataset = tf.data.Dataset.list_files(f\"{data_dir}/*\")\n\n    # Shuffle file paths, map load_and_preprocess_image, batch and prefetch\n    dataset = dataset.shuffle(shuffle_buffer_size)\n    dataset = dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.batch(batch_size, drop_remainder=True)\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)  # Prefetch for optimal loading\n\n    return dataset.repeat() ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:26:59.317508Z","iopub.execute_input":"2024-11-17T15:26:59.317842Z","iopub.status.idle":"2024-11-17T15:26:59.325322Z","shell.execute_reply.started":"2024-11-17T15:26:59.317817Z","shell.execute_reply":"2024-11-17T15:26:59.324635Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#load data\ndef load_image(file_path):\n    return np.array(Image.open(file_path))\n\ndef load_data(dataset_path):\n    files = [os.path.join(dataset_path, f) for f in os.listdir(dataset_path)]\n    with ThreadPoolExecutor() as executor:\n        data = list(tqdm(executor.map(load_image, files), total=len(files)))\n    return data\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:26:59.326218Z","iopub.execute_input":"2024-11-17T15:26:59.326500Z","iopub.status.idle":"2024-11-17T15:26:59.335531Z","shell.execute_reply.started":"2024-11-17T15:26:59.326476Z","shell.execute_reply":"2024-11-17T15:26:59.334825Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if USE_PIPELINING :\n    x_train = np.array(load_data(dataset_path))\n    image_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\nelse:\n    image_dataset = create_image_dataset(dataset_path, batch_size=BATCH_SIZE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:26:59.336392Z","iopub.execute_input":"2024-11-17T15:26:59.336648Z","iopub.status.idle":"2024-11-17T15:27:00.968277Z","shell.execute_reply.started":"2024-11-17T15:26:59.336625Z","shell.execute_reply":"2024-11-17T15:27:00.967024Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## display 25 photos in 5x5 format\ndef display_images(dataset, num_images=25):\n    images = []\n    for img_batch in dataset:\n        images.extend(img_batch[:num_images - len(images)])\n        if len(images) >= num_images:\n            break\n    \n    # Display images in a 5x5 grid\n    fig, ax = plt.subplots(5, 5, figsize=(10, 10))\n    for i in range(5):\n        for j in range(5):\n            ax[i, j].imshow(((images[5 * i + j]+1)*127.5).numpy().astype(int)) \n\n            ax[i, j].axis('off')\n    plt.tight_layout()\n    plt.show()\ndisplay_images(image_dataset)          ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:27:00.969463Z","iopub.execute_input":"2024-11-17T15:27:00.970171Z","iopub.status.idle":"2024-11-17T15:27:01.992590Z","shell.execute_reply.started":"2024-11-17T15:27:00.970135Z","shell.execute_reply":"2024-11-17T15:27:01.991464Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# create distributed dataset\ndef make_distributed(dataset):\n    dataset = tpu_strategy.experimental_distribute_dataset(dataset )\n    return  iter(dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:27:01.993819Z","iopub.execute_input":"2024-11-17T15:27:01.994213Z","iopub.status.idle":"2024-11-17T15:27:01.998068Z","shell.execute_reply.started":"2024-11-17T15:27:01.994172Z","shell.execute_reply":"2024-11-17T15:27:01.997251Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Definiation","metadata":{}},{"cell_type":"markdown","source":"## Helper Layers","metadata":{}},{"cell_type":"code","source":"# pixel-wise feature vector normalization layer\nclass PixelNormalization(Layer):\n    # initialize the layer\n    def __init__(self, **kwargs):\n        super(PixelNormalization, self).__init__(**kwargs)\n \n    # perform the operation\n    def call(self, inputs):\n        # computing pixel values\n\n        #Perform l2 norm\n        values = inputs**2.0\n        mean_values = tf.reduce_mean(values, axis=-1, keepdims=True)\n        mean_values += 1.0e-8\n        l2 = tf.sqrt(mean_values)\n        normalized = inputs / l2\n        return normalized\n \n    # define the output shape of the layer\n    def compute_output_shape(self, input_shape):\n        return input_shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T18:16:47.627612Z","iopub.execute_input":"2024-11-27T18:16:47.628307Z","iopub.status.idle":"2024-11-27T18:16:47.638700Z","shell.execute_reply.started":"2024-11-27T18:16:47.628266Z","shell.execute_reply":"2024-11-27T18:16:47.637398Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# mini-batch standard deviation layer\nclass MinibatchStdev(Layer):\n    # initialize the layer\n    def __init__(self, **kwargs):\n        super(MinibatchStdev, self).__init__(**kwargs)\n \n    # perform the operation\n    def call(self, inputs):\n        mean = tf.reduce_mean(inputs, axis=0, keepdims=True)\n        squ_diffs = tf.square(inputs - mean)\n        mean_sq_diff = tf.reduce_mean(squ_diffs, axis=0, keepdims=True)\n        mean_sq_diff += 1e-8\n        stdev = tf.sqrt(mean_sq_diff)\n        \n        mean_pix = tf.reduce_mean(stdev, keepdims=True)\n        shape = tf.shape(inputs)\n        output = tf.tile(mean_pix, (shape[0], shape[1], shape[2], 1))\n        \n        combined = tf.keras.backend.concatenate([inputs, output], axis=-1)\n        return combined\n \n    # define the output shape of the layer\n    def compute_output_shape(self, input_shape):\n        input_shape = list(input_shape)\n        input_shape[-1] += 1\n        return tuple(input_shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T18:16:47.639964Z","iopub.execute_input":"2024-11-27T18:16:47.640655Z","iopub.status.idle":"2024-11-27T18:16:47.664818Z","shell.execute_reply.started":"2024-11-27T18:16:47.640604Z","shell.execute_reply":"2024-11-27T18:16:47.663343Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# weighted sum output\nclass WeightedSum(Add):\n    # init with default value\n    def __init__(self, alpha=0.0, **kwargs):\n        super(WeightedSum, self).__init__(**kwargs)\n        self.alpha = tf.Variable(alpha, name='ws_alpha',trainable=False)\n \n    # output a weighted sum of inputs\n    def _merge_function(self, inputs):\n        # only supports a weighted sum of two inputs\n        assert (len(inputs) == 2)\n        # ((1-a) * input1) + (a * input2)\n        output = ((1.0 - self.alpha) * inputs[0]) + (self.alpha * inputs[1])\n        return output\n\n# update the alpha value on each instance of WeightedSum\ndef update_fadein(models, step, n_steps):\n    alpha = step / float(n_steps - 1)\n    for model in models:\n        for layer in model.layers:\n            if isinstance(layer, WeightedSum):\n                tf.keras.backend.set_value(layer.alpha, alpha)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T18:16:47.668296Z","iopub.execute_input":"2024-11-27T18:16:47.669351Z","iopub.status.idle":"2024-11-27T18:16:47.688259Z","shell.execute_reply.started":"2024-11-27T18:16:47.669262Z","shell.execute_reply":"2024-11-27T18:16:47.686816Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Generator","metadata":{}},{"cell_type":"code","source":"# adding a generator block\ndef add_generator_block(old_model,name):\n    init = tf.keras.initializers.RandomNormal(stddev=0.02)\n      #const = tf.keras.constraints.max_norm(1.0)\n    const  = None\n    block_end = old_model.layers[-3].output\n    \n    # upsample, and define new block\n    upsampling = UpSampling2D()(block_end)\n    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const, name=f\"{name}_Conv1\")(upsampling)\n    g = PixelNormalization(name=f\"{name}_PixelNorm1\")(g)\n    g = LeakyReLU(negative_slope=0.2, name=f\"{name}_LeakyReLU1\")(g)\n    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const, name=f\"{name}_Conv2\")(g)\n    g = PixelNormalization(name=f\"{name}_PixelNorm2\")(g)\n    g = LeakyReLU(negative_slope=0.2, name=f\"{name}_LeakyReLU2\")(g)\n    \n    out_image = Conv2D(3, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const, name=f\"{name}_RGB1\")(g)\n    out_image = Activation('tanh',name=f\"{name}_Activation\")(out_image)\n    model1 = Model(old_model.input, out_image,name = f\"{name}_normal\")\n    out_old = old_model.layers[-2]\n    out_image2 = out_old(upsampling)\n    out_image2 =  Activation('tanh',name=f\"{name}_Activation_Trin\")(out_image2)\n    \n    merged = WeightedSum()([out_image2, out_image])\n    model2 = Model(old_model.input, merged,name = f\"{name}_fadeIn\")\n    return [model1, model2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T18:32:08.929188Z","iopub.execute_input":"2024-11-27T18:32:08.929690Z","iopub.status.idle":"2024-11-27T18:32:08.941050Z","shell.execute_reply.started":"2024-11-27T18:32:08.929648Z","shell.execute_reply":"2024-11-27T18:32:08.939731Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# define generator models\ndef define_generator( n_blocks, in_dim=4):\n    init = tf.keras.initializers.RandomNormal(stddev=0.02)\n     #const = tf.keras.constraints.max_norm(1.0)\n    const  = None\n    model_list = list()\n    in_latent = Input(shape=(noise_dim,))\n    name = 'Block_0'\n    g  = Dense(128 * in_dim * in_dim, kernel_initializer=init, kernel_constraint=const,name = 'Dense1')(in_latent)\n    g = Reshape((in_dim, in_dim, 128),name = 'Reshape1')(g)\n    \n    # conv 4x4, input block\n    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const, name=f\"{name}_Conv1\")(g)\n    g = PixelNormalization(name=f\"{name}_PixelNorm1\")(g)\n    g = LeakyReLU(negative_slope=0.2, name=f\"{name}_LeakyReLU1\")(g)\n    \n    # conv 3x3\n    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const, name=f\"{name}_Conv2\")(g)\n    g = PixelNormalization(name=f\"{name}_PixelNorm2\")(g)\n    g = LeakyReLU(negative_slope=0.2, name=f\"{name}_LeakyReLU2\")(g)\n    \n    # conv 1x1, output block\n    out_image = Conv2D(3, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const,name=f\"{name}_RGB\")(g)\n    out_image = Activation('tanh',name=f\"{name}_Activation\")(out_image)\n    model = Model(in_latent, out_image)\n    model_list.append([model, model])\n    \n    for i in range(1, n_blocks):\n        old_model = model_list[i - 1][0]\n        models = add_generator_block(old_model,'Block_'+str(i))\n        model_list.append(models)\n        \n    return model_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T18:32:10.832078Z","iopub.execute_input":"2024-11-27T18:32:10.832638Z","iopub.status.idle":"2024-11-27T18:32:10.842946Z","shell.execute_reply.started":"2024-11-27T18:32:10.832589Z","shell.execute_reply":"2024-11-27T18:32:10.841574Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"## Discriminator","metadata":{}},{"cell_type":"code","source":"# adding a discriminator block\ndef add_discriminator_block(old_model, n_input_layers=3):\n    init = tf.keras.initializers.RandomNormal(stddev=0.02)\n    #const = tf.keras.constraints.max_norm(1.0)\n    const  = None\n    in_shape = list(old_model.input.shape)\n    \n    # define new input shape as double the size\n    input_shape = (in_shape[-2]*2, in_shape[-2]*2, in_shape[-1])\n    in_image = Input(shape=input_shape)\n    \n    # define new input processing layer\n    d = Conv2D(128, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(in_image)\n    d = LeakyReLU(alpha=0.2)(d)\n    \n    # define new block\n    d = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n    d = LeakyReLU(negative_slope=0.2)(d)\n    d = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n    d = LeakyReLU(negative_slope=0.2)(d)\n    d = AveragePooling2D((2,2))(d)\n    block_new = d\n    \n    # skip the input, 1x1 and activation for the old model\n    for i in range(n_input_layers, len(old_model.layers)):\n        d = old_model.layers[i](d)\n    model1 = Model(in_image, d)\n    \n    \n    downsample = AveragePooling2D((2,2))(in_image)\n    \n    block_old = old_model.layers[1](downsample)\n    block_old = old_model.layers[2](block_old)\n    d = WeightedSum()([block_old, block_new])\n    \n    for i in range(n_input_layers, len(old_model.layers)):\n        d = old_model.layers[i](d)\n        \n    model2 = Model(in_image, d)\n    return [model1, model2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T18:16:52.623203Z","iopub.execute_input":"2024-11-27T18:16:52.624304Z","iopub.status.idle":"2024-11-27T18:16:52.634909Z","shell.execute_reply.started":"2024-11-27T18:16:52.624260Z","shell.execute_reply":"2024-11-27T18:16:52.633289Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# define the discriminator models for each image resolution\ndef define_discriminator(n_blocks, input_shape=(4,4,3)):\n    init = tf.keras.initializers.RandomNormal(stddev=0.02)\n    #const = tf.keras.constraints.max_norm(1.0)\n    const  = None\n    model_list = list()\n    in_image = Input(shape=input_shape)\n    \n    d = Conv2D(128, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(in_image)\n    d = LeakyReLU(negative_slope=0.2)(d)\n    d = MinibatchStdev()(d)\n    \n    d = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    d = Conv2D(128, (4,4), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n    d = LeakyReLU(negative_slope=0.2)(d)\n    \n    d = Flatten()(d)\n    out_class = Dense(1)(d)\n    \n    model = Model(in_image, out_class)\n   \n    model_list.append([model, model])\n    \n    for i in range(1, n_blocks):\n        old_model = model_list[i - 1][0]\n        models = add_discriminator_block(old_model)\n        model_list.append(models)\n        \n    return model_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T18:16:54.594790Z","iopub.execute_input":"2024-11-27T18:16:54.595318Z","iopub.status.idle":"2024-11-27T18:16:54.606617Z","shell.execute_reply.started":"2024-11-27T18:16:54.595276Z","shell.execute_reply":"2024-11-27T18:16:54.604791Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Model data","metadata":{}},{"cell_type":"code","source":"with tpu_strategy.scope():\n    g_models = define_generator(no_blocks)\n    d_models = define_discriminator(no_blocks)\n\n\n    gen_training_loss = tf.keras.metrics.Mean('generator_training_loss', dtype=tf.float32)\n    disc_training_loss = tf.keras.metrics.Mean('critic_training_loss', dtype=tf.float32)\n    seed = tf.random.normal([num_examples_to_generate, noise_dim])\n    accuracy  = tf.keras.metrics.BinaryAccuracy()\n    generator_optimizer = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0, beta_2=0.99, epsilon=10e-8)\n    discriminator_optimizer = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0, beta_2=0.99, epsilon=10e-8)\n \n ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:27:06.641021Z","iopub.execute_input":"2024-11-17T15:27:06.641274Z","iopub.status.idle":"2024-11-17T15:27:11.178306Z","shell.execute_reply.started":"2024-11-17T15:27:06.641250Z","shell.execute_reply":"2024-11-17T15:27:11.177413Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def display_images_all(generator_list,disc_list,no_blocks,random = None):\n        if random is None:\n            random = tf.random.normal((1,noise_dim))\n\n        \n        \n        fig, axs = plt.subplots(no_blocks//3+1,3, figsize = (6,6))\n        \n        for i in range(no_blocks//3+1):\n            for j in range(3):\n                axs[i,j].axis('off')\n                if i*3+j >= no_blocks:\n                    continue\n                gen_imgs = generator_list[i*3+j][0](random,training =False)\n                axs[i, j].set_title('Shape = '+str(list(gen_imgs.shape)[1:]), fontsize=8)\n                axs[i, j].imshow((np.array(gen_imgs[0]) * 127.5 + 127.5).astype(int))\n                disc = disc_list[i*3+j][0](gen_imgs)\n                axs[i, j].text(0.5, -0.1, 'Discriminator rating = ' + str(int(disc)), fontsize=8, ha='center', transform=axs[i, j].transAxes)\n\n        \n       \n        plt.show()\n      \n        fig.savefig(save_train_loaction+\"/model/%models_output.png\" ,dpi=300)\n        plt.close(\"all\")\ndisplay_images_all(g_models,d_models,5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:27:11.179320Z","iopub.execute_input":"2024-11-17T15:27:11.179580Z","iopub.status.idle":"2024-11-17T15:27:12.315672Z","shell.execute_reply.started":"2024-11-17T15:27:11.179555Z","shell.execute_reply":"2024-11-17T15:27:12.314626Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training functions","metadata":{}},{"cell_type":"code","source":"@tf.function\ndef gradient_penalty(  real_images, fake_images,discriminator):\n        # Get the interpolated image\n        alpha = tf.random.uniform([len(fake_images), 1, 1, 1], 0.0, 1.0)\n       \n        \n        diff = fake_images - real_images\n        interpolated = real_images + alpha * diff\n\n        with tf.GradientTape() as gp_tape:\n            gp_tape.watch(interpolated)\n            pred = discriminator(interpolated, training=True)\n\n        grads = gp_tape.gradient(pred, [interpolated])[0]\n        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n        gp = tf.nn.compute_average_loss((norm - 1.0) ** 2,global_batch_size = len(fake_images)*tpu_strategy.num_replicas_in_sync)\n        return gp","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:27:12.316844Z","iopub.execute_input":"2024-11-17T15:27:12.317154Z","iopub.status.idle":"2024-11-17T15:27:12.323690Z","shell.execute_reply.started":"2024-11-17T15:27:12.317116Z","shell.execute_reply":"2024-11-17T15:27:12.322872Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generator loss for WGAN\n@tf.function\ndef generator_loss(fake_output):\n    return -tf.nn.compute_average_loss(fake_output,global_batch_size = len(fake_output)*tpu_strategy.num_replicas_in_sync)\n\n# Critic (discriminator) loss for WGAN\n@tf.function\ndef discriminator_loss(real_output, fake_output):\n    return tf.nn.compute_average_loss(fake_output - real_output,global_batch_size = len(fake_output)*tpu_strategy.num_replicas_in_sync)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:27:12.324772Z","iopub.execute_input":"2024-11-17T15:27:12.325104Z","iopub.status.idle":"2024-11-17T15:27:12.336040Z","shell.execute_reply.started":"2024-11-17T15:27:12.325060Z","shell.execute_reply":"2024-11-17T15:27:12.335385Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef train_step(Iter):\n   \n    def step_fn(images):\n        noise = tf.random.normal([len(images), noise_dim])\n        \n        with tf.GradientTape() as disc_tape:\n        \n               \n                generated_images = generator(noise, training=True)\n                real_output = discriminator(images, training=True)\n                   \n                fake_output = discriminator(generated_images, training=True)\n                disc_loss = discriminator_loss(real_output, fake_output)/2.0\n                gp = gradient_penalty( images, generated_images,discriminator)             \n                disc_loss = disc_loss + gp * GP_WEIGHT\n                \n        gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n\n        disc_training_loss.update_state(disc_loss * tpu_strategy.num_replicas_in_sync)\n        \n        accuracy.update_state(tf.zeros_like(fake_output), tf.where(fake_output > 0, 1, 0))\n        accuracy.update_state(tf.ones_like(real_output), tf.where(real_output > 0, 1, 0))\n        \n        # Train the generator once per step\n        with tf.GradientTape() as gen_tape:\n                noise = tf.random.normal([ len(images), noise_dim])\n                generated_images = generator(noise, training=True)\n                real_output = discriminator(images, training=True)\n               \n                fake_output = discriminator(generated_images, training=True)\n                disc_loss = discriminator_loss(real_output, fake_output)\n                gen_loss = generator_loss(fake_output)\n          \n        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n        \n        \n        gen_training_loss.update_state(gen_loss * tpu_strategy.num_replicas_in_sync)\n        \n\n\n    \n    tpu_strategy.run(step_fn, args=(next(Iter),))       \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:27:12.339498Z","iopub.execute_input":"2024-11-17T15:27:12.340061Z","iopub.status.idle":"2024-11-17T15:27:12.350756Z","shell.execute_reply.started":"2024-11-17T15:27:12.340033Z","shell.execute_reply":"2024-11-17T15:27:12.349939Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"##checkpointing\n\ncheckpoint_dir = save_train_loaction+'/model'\nlast_epoch = tf.Variable(0, name='last_epoch', trainable=False)\n\nCurrent_Block_no = tf.Variable(0, name='Current_Block_no', trainable=False)\n\nbest_fid_score = tf.Variable(np.inf, name='best_fid_score', trainable=False)\ncheckpoint = tf.train.Checkpoint(\n                                 generator=g_models,\n                                 discriminator=d_models,\n                                 last_epoch = last_epoch,\n                                best_fid_score =best_fid_score,\n                                 Current_Block_no =Current_Block_no\n                                )\n\n\n## initializes the output manager with output directory and checks if there is any more recent waits\n\nmanager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=3)\ncheckpoint.restore(manager.latest_checkpoint)\nif manager.latest_checkpoint:\n    print(\"Restored from {}\".format(manager.latest_checkpoint))\n    print(\"Starting from Block no:\", int(Current_Block_no))\nelse:\n    print(\"Current Checkpoint Location Empty as Well\")\n    print(\"Initializing from scratch.\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:27:12.351567Z","iopub.execute_input":"2024-11-17T15:27:12.351815Z","iopub.status.idle":"2024-11-17T15:27:12.376748Z","shell.execute_reply.started":"2024-11-17T15:27:12.351791Z","shell.execute_reply":"2024-11-17T15:27:12.375996Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def save_images(generator,epoch,random = None,fadeIn = False):\n        if random is None:\n            random = tf.random.normal((9,noise_dim))\n\n        gen_imgs = generator(random,training =False)\n        \n        \n        fig, axs = plt.subplots(3,3, figsize = (6,6))\n        \n        for i in range(3):\n            for j in range(3):\n                axs[i, j].imshow((np.array(gen_imgs[3 * i + j]) * 127.5 + 127.5).astype(int))\n                axs[i,j].axis('off')\n        plt.suptitle('Shape = '+str(list(gen_imgs.shape)[1:]))\n       \n        plt.show()\n        if epoch%ImageSaveInterval == 0 :\n            if fadeIn:\n                fig.savefig(save_train_loaction+f\"/images/{epoch}-fadIn-{str(list(gen_imgs.shape)[1:])}.png\"  ,dpi=300)\n            else:\n                fig.savefig(save_train_loaction+f\"/images/{epoch}-{str(list(gen_imgs.shape)[1:])}.png\"  ,dpi=300)\n        plt.close(\"all\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:27:12.377657Z","iopub.execute_input":"2024-11-17T15:27:12.378215Z","iopub.status.idle":"2024-11-17T15:27:12.384432Z","shell.execute_reply.started":"2024-11-17T15:27:12.378185Z","shell.execute_reply":"2024-11-17T15:27:12.383653Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef trainer(gen,disc,dataset, epochs,fadein = False):\n                global generator,discriminator,generator_optimizer,discriminator_optimizer\n                generator = gen\n                discriminator = disc\n                progress_bar = tqdm(range(0,epochs))\n                with tpu_strategy.scope():\n                    generator_optimizer = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0, beta_2=0.99, epsilon=10e-8)\n                    discriminator_optimizer = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0, beta_2=0.99, epsilon=10e-8)\n                  \n                compiled_train_step = tf.function(train_step)\n                for steps in progress_bar:\n                        progress_bar.set_description(f\"Epoch {steps}\")\n                        for j in range(steps_per_epoch):\n                        # Run step function with a distribution strategy\n                            if fadein:\n                                update_fadein([generator, discriminator], float(steps*steps_per_epoch+j), epochs*steps_per_epoch)\n                        \n                            compiled_train_step(dataset)\n                            if j%1000 == 0:\n                                progress_bar.set_postfix({\n                                    'Generator Loss': f\"{gen_training_loss.result():.4f}\",\n                                    'Discriminator Loss': f\"{disc_training_loss.result():.4f}\",\n                                     'Accuracy': f\"{accuracy.result():.4f}\"\n                                    \n                                })\n                        last_epoch.assign(steps+1)\n                            # Save the model every 15 epochs\n                        if steps  % CheckpointInterval == 0:\n                            print(\"Saving current progress\")  \n                            #save_best_fid_score()\n                            manager.save()\n                        if steps%OutputInterval == 0:\n                            display.clear_output(wait=False)\n                            save_images(generator, steps,seed,fadein)\n                        \n                            gen_training_loss.reset_state()\n                            disc_training_loss.reset_state\n                            accuracy.reset_state()\n              \n# train the generator and discriminator\ndef train(g_models, d_models, dataset, epochs,n_batch):\n    if int(Current_Block_no) == 0:\n        g_normal, d_normal = g_models[0][0], d_models[0][0]\n        gen_shape = g_normal.output_shape\n        scaled_data = change_dataset((gen_shape[1],gen_shape[1]),n_batch[0],dataset ).repeat()\n        scaled_data = make_distributed(scaled_data)\n        print('Scaled Data', gen_shape)\n    \n        \n        # train normal or straight-through models\n        trainer(g_normal, d_normal,  scaled_data,epochs[0])\n        Current_Block_no.assign(Current_Block_no+1)\n        \n    # process each level of growth\n    for i in range(int(Current_Block_no), len(g_models)):\n        # retrieve models for this level of growth\n        [g_normal, g_fadein] = g_models[i]\n        [d_normal, d_fadein] = d_models[i]\n        \n        \n        # scale dataset to appropriate size\n        gen_shape = g_normal.output_shape\n        scaled_data = change_dataset((gen_shape[1],gen_shape[1]),n_batch[0],dataset ).repeat()\n        scaled_data = make_distributed(scaled_data)\n        print('Scaled Data', gen_shape)\n        \n        # train fade-in models for next level of growth\n        trainer(g_fadein, d_fadein, scaled_data,epochs[i],  True)\n        \n        # train normal or straight-through models\n        trainer(g_normal, d_normal, scaled_data,epochs[i])\n        Current_Block_no.assign(Current_Block_no+1)\n      ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:27:12.385336Z","iopub.execute_input":"2024-11-17T15:27:12.385580Z","iopub.status.idle":"2024-11-17T15:27:12.400016Z","shell.execute_reply.started":"2024-11-17T15:27:12.385556Z","shell.execute_reply":"2024-11-17T15:27:12.399351Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#save_best_fid_score()\n          \ntrain(g_models,d_models,image_dataset, Epochs,n_batch)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T15:27:12.400875Z","iopub.execute_input":"2024-11-17T15:27:12.401130Z","iopub.status.idle":"2024-11-17T17:40:23.783648Z","shell.execute_reply.started":"2024-11-17T15:27:12.401107Z","shell.execute_reply":"2024-11-17T17:40:23.782507Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"display_images_all(g_models,d_models,no_blocks)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T17:40:23.785626Z","iopub.execute_input":"2024-11-17T17:40:23.785978Z","iopub.status.idle":"2024-11-17T17:40:24.687950Z","shell.execute_reply.started":"2024-11-17T17:40:23.785945Z","shell.execute_reply":"2024-11-17T17:40:24.686902Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"display_images_all(g_models,d_models,no_blocks)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_images(generator,1,seed)\nsave_best_fid_score(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T17:40:24.689182Z","iopub.execute_input":"2024-11-17T17:40:24.689926Z","iopub.status.idle":"2024-11-17T17:40:26.091034Z","shell.execute_reply.started":"2024-11-17T17:40:24.689888Z","shell.execute_reply":"2024-11-17T17:40:26.089840Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Generator = g_models[no_blocks-1][0]\nDisciminator = d_models[no_blocks-1][0]\nGenerator.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T17:52:45.258297Z","iopub.execute_input":"2024-11-17T17:52:45.259154Z","iopub.status.idle":"2024-11-17T17:52:45.299694Z","shell.execute_reply.started":"2024-11-17T17:52:45.259120Z","shell.execute_reply":"2024-11-17T17:52:45.298876Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Disciminator = d_models[no_blocks-1][0]\nDisciminator.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T17:59:54.787200Z","iopub.execute_input":"2024-11-17T17:59:54.787593Z","iopub.status.idle":"2024-11-17T17:59:54.822182Z","shell.execute_reply.started":"2024-11-17T17:59:54.787563Z","shell.execute_reply":"2024-11-17T17:59:54.821353Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with tpu_strategy.scope():\n    Generator.save('Generator.keras')\n    Disciminator.save('Disciminator.keras')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T18:05:34.345154Z","iopub.execute_input":"2024-11-17T18:05:34.346147Z","iopub.status.idle":"2024-11-17T18:05:34.571743Z","shell.execute_reply.started":"2024-11-17T18:05:34.346105Z","shell.execute_reply":"2024-11-17T18:05:34.570665Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Generator.output.shape[1:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T18:01:37.904657Z","iopub.execute_input":"2024-11-17T18:01:37.905718Z","iopub.status.idle":"2024-11-17T18:01:37.910893Z","shell.execute_reply.started":"2024-11-17T18:01:37.905680Z","shell.execute_reply":"2024-11-17T18:01:37.910045Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def save_all_models(models,name):\n    for i in range(len(models)):\n        with tpu_strategy.scope():\n            models[i][0].save(f\"{save_train_loaction}/model/{name}-{models[i][0].output.shape[1:]}-Block_no{i}.keras\")\n            models[i][1].save(f\"{save_train_loaction}/model/{name}-{models[i][1].output.shape[1:]}-Intermidate-Block_no{i}.keras\")\nsave_all_models(g_models,'Generator')\nsave_all_models(d_models,'Discriminator')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T18:08:39.037723Z","iopub.execute_input":"2024-11-17T18:08:39.038183Z","iopub.status.idle":"2024-11-17T18:08:40.300055Z","shell.execute_reply.started":"2024-11-17T18:08:39.038147Z","shell.execute_reply":"2024-11-17T18:08:40.298964Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def save_all_models_images(models,name):\n    for i in range(len(models)):\n        plot_model(\n            models[i][0],                  # Your TensorFlow model\n            to_file=f\"{name}-{models[i][0].output.shape[1:]}-Block_no{i}.png\",  # File to save the image\n            show_shapes=True,       # Display tensor shapes\n            show_layer_names=True,  # Display layer names\n            expand_nested=False,     # Expand nested models (useful for complex architectures)\n            rankdir=\"TB\",  # Top-to-Bottom layout; use \"LR\" for Left-to-Right\n            dpi=96                  # Adjust for higher resolution\n        )\n        plot_model(\n            models[i][1],                  # Your TensorFlow model\n            to_file=f\"{name}-{models[i][1].output.shape[1:]}-Intermidate-Block_no{i}.png\",  # File to save the image\n            show_shapes=True,       # Display tensor shapes\n            show_layer_names=True,  # Display layer names\n            expand_nested=False,     # Expand nested models (useful for complex architectures)\n            rankdir=\"TB\",  # Top-to-Bottom layout; use \"LR\" for Left-to-Right\n            dpi=96                  # Adjust for higher resolution\n        )\n\nsave_all_models_images(g_models,'Generator')\nsave_all_models_images(d_models,'Discriminator')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T18:46:06.331288Z","iopub.execute_input":"2024-11-27T18:46:06.332705Z","iopub.status.idle":"2024-11-27T18:46:14.818255Z","shell.execute_reply.started":"2024-11-27T18:46:06.332650Z","shell.execute_reply":"2024-11-27T18:46:14.816962Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"!apt install zip\n!zip -r data.zip ./","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T18:10:04.765317Z","iopub.execute_input":"2024-11-17T18:10:04.765805Z","iopub.status.idle":"2024-11-17T18:10:20.782893Z","shell.execute_reply.started":"2024-11-17T18:10:04.765768Z","shell.execute_reply":"2024-11-17T18:10:20.781673Z"},"scrolled":true},"outputs":[],"execution_count":null}]}